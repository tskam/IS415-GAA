---
title: "Geographically Weighted Predictive Models: Geographical Random Forest (grf) methods"
date: "March 9, 2024"
date-modified: "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning: false
  freeze: true
---

## Learning outcome

In this in-class exercise, you will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:

-   preparing training and test data sets by using appropriate data sampling methods,
-   calibrating predictive models by using both geospatial statistical learning and machine learning methods,
-   comparing and selecting the best model for predicting the future outcome,
-   predicting the future outcomes by using the best model calibrated.

## Installing and Loading R packages

This code chunk performs 3 tasks:

-   A list called packages will be created and will consists of all the R packages required to accomplish this exercise.
-   Check if R packages on package have been installed in R and if not, they will be installed.
-   After all the R packages have been installed, they will be loaded.

```{r}
pacman::p_load(sf, spdep, GWmodel,
               SpatialML, tmap, 
               tidymodels, tidyverse, 
               gtsummary,
               rpart, rpart.plot, 
               ggstatsplot, performance)
```

## The Data

### Reading data file to rds

Reading the input data sets. It is in simple feature data frame.

```{r}
rs_sf <- read_rds("data/rds/HDB_resale.rds")
```

Next, the code chunk below is used to reveal the properties of *rs_sf* object.

```{r}
rs_sf
```

Notice that it is a sf tibble data.frame. The are a total of 15901 observation and 18 columns (i.e. variables) including the geometry column.

### Data Sampling

For predictive modelling, we need to have at least two sets of data, one to train the algorithm and the other one will be used for model comparison.

::: panel-tabset
## The task

Split *rs_sf* into training and test data sets into with 50% and 50% respectively by using appropriate function of **rsample** package.

## The code chunk

```{r}
set.seed(1234)
resale_split <- initial_split(
  rs_sf, 
  prop = 5/10,)
train_sf <- training(resale_split)
test_sf <- testing(resale_split)
```
:::

### Converting from sf objects to data.frame gwModel and spatial ML libraries require the input data

```{r}
#| eval: false
train_df <- train_sf %>%
  st_drop_geometry() %>%
  as.data.frame()

test_df <- test_sf %>%
  st_drop_geometry() %>%
  as.data.frame()
```

### Saving the output files

```{r}
#| eval: false
write_rds(train_df, "data/rds/train_df.rds")
write_rds(test_df, "data/rds/test_df.rds")
```

## Retriving the Stored Data

```{r}
train_df <- read_rds("data/rds/train_df.rds")
test_df <- read_rds("data/rds/test_df.rds")
```

## Computing Correlation Matrix

Before loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.

```{r}
#| fig-width: 12
#| fig-height: 12
rs_sf1 <- rs_sf %>%
  st_drop_geometry()
ggcorrmat(rs_sf1[, 2:17]) 
```

::: callout-note
The correlation matrix above shows that all the correlation values are below 0.8. Hence, there is no sign of multicolinearity.
:::

## Building a Non-spatial Multiple Linear Regression

```{r}
rs_mlr <- lm(formula = RESALE_PRICE ~ 
               FLOOR_AREA_SQM +
               STOREY_ORDER +
               REMAINING_LEASE_MTHS +
               PROX_CBD + 
               PROX_ELDERLYCARE + 
               PROX_HAWKER +
               PROX_MRT + 
               PROX_PARK + 
               PROX_GOOD_PRISCH +
               PROX_MALL + 
               PROX_CHAS +
               PROX_SUPERMARKET +
               WITHIN_350M_KINDERGARTEN +
               WITHIN_350M_CHILDCARE +
               WITHIN_350M_BUS +
               WITHIN_1KM_PRISCH,
             data=train_df)
```

```{r}
tbl_regression(rs_mlr, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

```{r}
p <- performance::check_collinearity(
  rs_mlr)
plot(p)

```

### Revising mlr model

```{r}
train_df <- train_df %>%
  select(-c(PROX_CHAS))
train_sf <- train_sf %>%
  select(-c(PROX_CHAS))
test_df <- test_df %>%
  select(-c(PROX_CHAS))
test_sf <- test_sf %>%
  select(-c(PROX_CHAS))
```

```{r}
#| eval: false
write_rds(train_sf, "data/rds/train_sf.rds")
write_rds(train_df, "data/rds/train_df.rds")
write_rds(test_sf, "data/rds/test_sf.rds")
write_rds(test_df, "data/rds/test_df.rds")
```

```{r}
rs_mlr <- lm(formula = RESALE_PRICE ~ 
               FLOOR_AREA_SQM +
               STOREY_ORDER +
               REMAINING_LEASE_MTHS +
               PROX_CBD + 
               PROX_ELDERLYCARE + 
               PROX_HAWKER +
               PROX_MRT + 
               PROX_PARK + 
               PROX_GOOD_PRISCH +
               PROX_MALL + 
               PROX_SUPERMARKET +
               WITHIN_350M_KINDERGARTEN +
               WITHIN_350M_CHILDCARE +
               WITHIN_350M_BUS +
               WITHIN_1KM_PRISCH,
             data=train_df)
```

```{r}
tbl_regression(rs_mlr, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

```{r}
#| eval: false 
write_rds(rs_mlr, 
          "data/models/rs_mlr.rds" ) 
```

## Converting the sf data.frame to SpatialPointDataFrame

### The training data

```{r}
train_sp <- as_Spatial(train_sf)
train_sp
```

### The test data

```{r}
test_sp <- test_sf %>%
  as_Spatial()
test_sp
```

## Preparing Data for Predictive Modelling

### Extracting coordinates data

The code chunk below extract the x,y coordinates of the full, training and test data sets.

```{r}
coords <- st_coordinates(rs_sf)
coords_train <- st_coordinates(train_sf)
coords_test <- st_coordinates(test_sf)
```

Before continue, we write all the output into rds for future used.

```{r}
coords_train <- write_rds(coords_train, "data/models/coords_train.rds" )
coords_test <- write_rds(coords_test, "data/models/coords_test.rds" )
```

### Droping geometry field

First, we will drop geometry column of the sf data.frame by using `st_drop_geometry()` of sf package.

```{r}
train_df <- train_sf %>% 
  st_drop_geometry()
```

## Calibrating Predictive Model: Recursive Partitioning method

```{r}
set.seed(1234)
rs_rp <- rpart(
  formula = RESALE_PRICE ~ 
    FLOOR_AREA_SQM +
    STOREY_ORDER +
    REMAINING_LEASE_MTHS +
    PROX_CBD + 
    PROX_ELDERLYCARE + 
    PROX_HAWKER +
    PROX_MRT + 
    PROX_PARK + 
    PROX_GOOD_PRISCH +
    PROX_MALL + 
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN +
    WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS +
    WITHIN_1KM_PRISCH,
    data = train_df)
rs_rp
```

```{r}
rpart.plot(rs_rp)

```

## Calibrating Random Forest Model

In this section, you will learn how to calibrate a model to predict HDB resale price by using random forest function of [**ranger**](https://cran.r-project.org/web/packages/ranger/index.html) package.

```{r}
set.seed(1234)
rs_rf <- ranger(formula = RESALE_PRICE ~ 
    FLOOR_AREA_SQM +
    STOREY_ORDER +
    REMAINING_LEASE_MTHS +
    PROX_CBD + 
    PROX_ELDERLYCARE + 
    PROX_HAWKER +
    PROX_MRT + 
    PROX_PARK + 
    PROX_GOOD_PRISCH +
    PROX_MALL + 
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN +
    WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS +
    WITHIN_1KM_PRISCH,
    data=train_df,
    importance = "impurity")
rs_rf
```

```{r}
#| eval: false
#| echo: false
write_rds(rs_rf, "data/models/rs_rf.rds")
```

```{r}
#| echo: false
#| eval: false
rs_rf <- read_rds("data/models/rs_rf.rds")
rs_rf
```

```{r}
vi <- as.data.frame(rs_rf$variable.importance)
vi$variables <- rownames(vi)
vi <- vi %>%
  rename(vi = "rs_rf$variable.importance")
```

```{r}
ggplot(data = vi,
       aes(x = vi, 
           y = reorder(variables, vi))) + 
  geom_bar(stat="identity")
```

## Calibrating Geographical Random Forest Model

In this section, you will learn how to calibrate a model to predict HDB resale price by using `grf()` of [**SpatialML**](https://cran.r-project.org/web/packages/ranger/index.html) package.

### Calibrating using training data

```{r}
#| eval: false
grf_bw_adp <- grf.bw(
  formula = RESALE_PRICE ~ 
    FLOOR_AREA_SQM +
    STOREY_ORDER +
    REMAINING_LEASE_MTHS +
    PROX_CBD + 
    PROX_ELDERLYCARE + 
    PROX_HAWKER +
    PROX_MRT + 
    PROX_PARK + 
    PROX_GOOD_PRISCH +
    PROX_MALL + 
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN +
    WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS +
    WITHIN_1KM_PRISCH,
    dataset = train_df,
    kernel= "adaptive",
    coords= coords_train,
    bw.min = 25,
    bw.max = 60,
    step = 1,
    nthreads = 16,
    forest = FALSE,
    weighted = TRUE)
```

::: callout-tip
The procedure above is very time consuming. It is a good practice to save the output and stop the running the code chunk in future
:::

The code chunk below calibrate a geographic random forest model by using `grf()` of **SpatialML** package.

```{r}
#| eval: false
set.seed(1234)
rs_grf <- grf(formula = RESALE_PRICE ~ 
    FLOOR_AREA_SQM +
    STOREY_ORDER +
    REMAINING_LEASE_MTHS +
    PROX_CBD + 
    PROX_ELDERLYCARE + 
    PROX_HAWKER +
    PROX_MRT + 
    PROX_PARK + 
    PROX_MALL + 
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN +
    WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS +
    WITHIN_1KM_PRISCH,
    dframe=train_df, 
    bw=55,
    kernel="adaptive",
    coords=coords_train)
```

::: callout-tip
The procedure above is very time consuming. It is a good practice to save the output and stop the running the code chunk in future
:::

Let's save the model output by using the code chunk below.

```{r}
#| eval: false
write_rds(rs_grf, 
          "data/models/rs_grf.rds")
```

The code chunk below can be used to retrieve the save model in future.

```{r}
rs_grf <- read_rds("data/models/rs_grf.rds")
```

### Predicting by using test data

#### Preparing the test data

The code chunk below will be used to combine the test data with its corresponding coordinates data.

```{r}
test_df <- cbind(test_sf, coords_test) %>%
  st_drop_geometry()
```

## Predicting with test data

Next, `predict.grf()` of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.

```{r}
#| eval: false
grf_pred <- predict.grf(rs_grf, 
                        test_df,
                        x.var.name="X",
                        y.var.name="Y", 
                        local.w=1,
                        global.w=0)
```

::: callout-tip
The procedure above is very time consuming. It is a good practice to save the output and stop the running the code chunk in future
:::

Before moving on, let us save the output into rds file for future use.

```{r}
#| eval: false
grf_pred <- write_rds(grf_pred, 
                      "data/models/grf_pred.rds")
```

### Saving predicted output of geographic random forest and preparing final data table

The output of the `predict.grf()` is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.

```{r}
grf_pred <- read_rds("data/models/grf_pred.rds")
grf_pred_df <- as.data.frame(grf_pred)
```

In the code chunk below, `cbind()` is used to append the predicted values onto test_df the

```{r}
test_pred <- test_df %>%
  select(RESALE_PRICE) %>% 
  cbind(grf_pred_df)
```

### Saving predicted output of random forest and preparing final data table

```{r}
rf_pred <- predict(rs_rf, test_df)
```

```{r}
rf_pred_df <- as.data.frame(rf_pred$predictions) %>%
  rename(rf_pred = "rf_pred$predictions")
```

```{r}
test_pred <- cbind(test_pred, 
                   rf_pred_df)
```

### Saving predicted output of multiple linear regression and preparing final data table

```{r}
mlr_pred <- predict(rs_mlr, test_df)
```

```{r}
mlr_pred_df <- as.data.frame(mlr_pred) %>%
  rename(mlr_pred = "mlr_pred")
```

```{r}
test_pred <- cbind(test_pred, 
                   mlr_pred_df)
```

```{r}
#| eval: false
write_rds(test_pred, 
          "data/models/test_pred.rds")
```

## Model Comparison

The root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.

```{r}
#| echo: false
test_pred <- read_rds("data/models/test_pred.rds")
```

```{r}
yardstick::rmse(test_pred, 
                RESALE_PRICE, 
                grf_pred)
```

```{r}
yardstick::rmse(test_pred, 
                RESALE_PRICE, 
                rf_pred)
```

```{r}
yardstick::rmse(test_pred, 
                RESALE_PRICE, 
                mlr_pred)
```

```{r}
mc <- test_pred %>%
  pivot_longer(cols = c(2:4),
               names_to = "models",
               values_to = "predicted")

```

```{r}
mc %>% 
  group_by(models) %>%
  yardstick::rmse(RESALE_PRICE, 
                  predicted)
```

### Visualising the predicted values

Alternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.

```{r}
ggplot(data = test_pred,
       aes(x = grf_pred,
           y = RESALE_PRICE)) +
  geom_point()
```

::: callout-note
A better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.
:::

In the code chunk below, `facet_grid()` of **ggplot** package is used to display the scatterplots next to each other.

```{r}
#| fig-width: 12
ggplot(data = mc,
       aes(x = predicted,
           y = RESALE_PRICE)) +
  geom_point() +
  facet_grid(. ~ models)
```


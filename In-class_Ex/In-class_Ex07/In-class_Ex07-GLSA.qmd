---
title: "In-class Exercise 7: Global and Local Measures of Spatial Association - sfdep methods"
author: "Dr. Kam Tin Seong"
format: 
  html:
    fontsize: 20px
execute: 
  echo: true
  eval: true
  warning: false
editor: visual     
---

## Overview

This in-class introduces an alternative R package to spdep package you used in [Chapter 9: Global Measures of Spatial Autocorrelation](https://r4gdsa.netlify.app/chap09.html) and [Chapter 10: Local Measures of Spatial Autocorrelation](https://r4gdsa.netlify.app/chap10.html). The package is called [**sfdep**](https://sfdep.josiahparry.com/index.html). According to Josiah Parry, the developer of the package, "sfdep builds on the great shoulders of **spdep** package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible."

## Getting started

### Installing and Loading the R Packages

Four R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, install and load **sf**, **tmap**, **sfdep** and **tidyverse** packages into R environment.
:::

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
pacman::p_load(sf, sfdep, tmap, tidyverse)
```
:::

## The Data

For the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:

-   Hunan, a geospatial data set in ESRI shapefile format, and
-   Hunan_2012, an attribute data set in csv format.

### Importing geospatial data

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, import *Hunan* shapefile into R environment as an sf data frame.
:::

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```
:::

### Importing attribute table

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, import *Hunan_2012.csv* into R environment as an tibble data frame.
:::

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```
:::

### Combining both data frame by using left join

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, combine the Hunan sf data frame and Hunan_2012 data frame. Ensure that the output is an sf data frame.
:::

::: callout-important
In order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)
:::

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
hunan_GDPPC <- left_join(hunan, hunan2012) %>%
  select(1:4, 7, 15)
```
:::

### Plotting a choropleth map

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, plot a choropleth map showing the distribution of GDPPC of Hunan Province.
:::

The choropleth should look similar to the figure below.

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-width: 10
#| fig-height: 8
tmap_mode("plot")
tm_shape(hunan_GDPPC) +
  tm_fill("GDPPC", 
          style = "quantile", 
          palette = "Blues",
          title = "GDPPC") +
  tm_layout(main.title = "Distribution of GDP per capita by district, Hunan Province",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```
:::

## Global Measures of Spatial Association

### Step 1: Deriving contiguity weights: Queen's method

::: callout-note
# Do it Yourself!

Using the steps you learned in previous lesson, derive a Queen's contiguity weights by using appropriate spdep and tidyverse functions.
:::

### Deriving contiguity weights: Queen's method

In the code chunk below, queen method is used to derive the contiguity weights.

::: {style="font-size: 1.5em"}
```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1) 
```
:::

Notice that `st_weights()` provides tree arguments, they are:

-   *nb*: A neighbor list object as created by st_neighbors().
-   *style*: Default "W" for row standardized weights. This value can also be "B", "C", "U", "minmax", and "S". B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).
-   *allow_zero*: If TRUE, assigns zero as lagged value to zone without neighbors.

::: {style="font-size: 1.5em"}
```{r}
wm_q
```
:::

### Computing Global Moran' I

::: {style="font-size: 1.5em"}
```{r}
moranI <- global_moran(wm_q$GDPPC,
                       wm_q$nb,
                       wm_q$wt)
```
:::

### Performing Global Moran'I test

::: {style="font-size: 1.5em"}
```{r}
global_moran_test(wm_q$GDPPC,
                       wm_q$nb,
                       wm_q$wt)
```
:::

### Performing Global Moran'I permutation test

```{r}
set.seed(1234)
```

::: {style="font-size: 1.5em"}
```{r}
global_moran_perm(wm_q$GDPPC,
                       wm_q$nb,
                       wm_q$wt,
                  nsim = 99)
```
:::

## Computing local Moran's I

::: {style="font-size: 1.5em"}
```{r}
lisa <- wm_q %>% 
  mutate(local_moran = local_moran(
    GDPPC, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)
lisa
```
:::

### Visualising local Moran's I

::: {style="font-size: 1.5em"}
```{r}
#| fig-width: 8
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8))
```
:::

### Visualising p-value of local Moran's I

::: {style="font-size: 1.5em"}
```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("p_ii") + 
  tm_borders(alpha = 0.5)
```
:::

### Visuaising local Moran's I and p-value

For effective comparison, you can plot both maps next to each other as shown below.

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)

```
:::

## Visualising local Moran's I

::: {style="font-size: 1.5em"}
```{r}
lisa_sig <- lisa  %>%
  filter(p_ii < 0.05)
tmap_mode("plot")
tm_shape(lisa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```
:::

## Hot Spot and Cold Spot Area Analysis

## Computing local Moran's I

::: {style="font-size: 1.5em"}
```{r}
HCSA <- wm_q %>% 
  mutate(local_Gi = local_gstar_perm(
    GDPPC, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
HCSA
```
:::

### Visualising Gi\*

::: {style="font-size: 1.5em"}
```{r}
#| fig-width: 8
tmap_mode("plot")
tm_shape(HCSA) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8))
```
:::

### Visualising p-value of HCSA

::: {style="font-size: 1.5em"}
```{r}
tmap_mode("plot")
tm_shape(HCSA) +
  tm_fill("p_sim") + 
  tm_borders(alpha = 0.5)
```
:::

### Visuaising local HCSA

For effective comparison, you can plot both maps next to each other as shown below.

::: {style="font-size: 1.5em"}
```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
map1 <- tm_shape(HCSA) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of GDPPC",
            main.title.size = 0.8)

map2 <- tm_shape(HCSA) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi*",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)

```
:::

## Visualising local Moran's I

::: {style="font-size: 1.5em"}
```{r}
lisa_sig <- lisa  %>%
  filter(p_ii < 0.05)
tmap_mode("plot")
tm_shape(lisa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```
:::

### Deriving contiguity weights: Rooks method

::: callout-note
# Do It Yourself!

Using the steps you just learned, derive a contiguity weights using Rooks method.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
wm_r <- hunan %>%
  mutate(nb = st_contiguity(geometry,
                            queen = FALSE),
         wt = st_weights(nb),
         .before = 1) 
```

## Distance-based Weights

There are three popularly used distance-based spatial weights, they are:

-   fixed distance weights,
-   adaptive distance weights, and
-   inverse distance weights (IDW).

### Deriving fixed distance weights

Before we can derive the fixed distance weights, we need to determine the upper limit for distance band by using the steps below:

```{r}
geo <- sf::st_geometry(hunan_GDPPC)
nb <- st_knn(geo, longlat = TRUE)
dists <- unlist(st_nb_dists(geo, nb))
```

::: callout-tip
# Things to learn from the code chunk above

-   [`st_nb_dists()`](https://sfdep.josiahparry.com/reference/st_nb_dists.html) of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation's neighbors list.
-   [`unlist()`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist) of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.
:::

Now, we will go ahead to derive summary statistics of the nearest neighbour distances vector (i.e. dists) by usign the coced chunk below.

```{r}
summary(dists)
```

The summary statistics report above shows that the maximum nearest neighbour distance is 65.80km. By using a threshold value of 66km will ensure that each area will have at least one neighbour.

Now we will go ahead to compute the fixed distance weights by using the code chunk below.

```{r}
wm_fd <- hunan_GDPPC %>%
  dplyr::mutate(nb = st_dist_band(geometry,
                                  upper = 66),
               wt = st_weights(nb),
               .before = 1)
```

::: callout-tip
# Things to learn from the code chunk above

-   [`st_dists_band()`](https://sfdep.josiahparry.com/reference/st_dist_band.html) of sfdep is used to identify neighbors based on a distance band (i.e. 66km). The output is a list of neighbours (i.e. nb).
-   [`st_weights()`](https://sfdep.josiahparry.com/reference/st_weights.html) is then used to calculate polygon spatial weights of the nb list. Note that:
    -   the default `style` argument is set to "W" for row standardized weights, and
    -   the default `allow_zero` is set to TRUE, assigns zero as lagged value to zone without neighbors.
:::

::: callout-note
# Do It Yourself

Using the steps you learned in previous section, examine the data frame of the fixed distance weights.
:::

## Deriving adaptive distance weights

In this section you will learn how to derive an adaptive distance weights.

```{r}
wm_ad <- hunan_GDPPC %>% 
  mutate(nb = st_knn(geometry,
                     k=8),
         wt = st_weights(nb),
               .before = 1)
```

### Calculate inverse distance weights

```{r}
#| eval: false
wm_idw <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```

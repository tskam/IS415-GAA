---
title: "R for Geospatial Data Sceince"
format: 
  html:
    code-fold: true
    code-summary: "Show the code"
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

## Getting Started

::: callout-note
### DIY

Using the step you learned in previous lesson,

-   create a folder called In-class_Ex02.

-   create a new Quarto document called In-class_Ex02.
:::

In this hands-on exercise, the following R packages will be used.

-   [arrow](https://arrow.apache.org/docs/r/) exposes an interface to the Arrow C++ library, enabling access to many of its features in R.  For this in-class exercise, arrow will be used to read Parquet files into R environment.
-   [lubridate](https://lubridate.tidyverse.org/index.html), a member of tidyverse family.  Lubridate makes it easier to do the things R does with date-times and possible to do the things R does not.  If you are new to lubridate, the best place to start is the [Date and times](https://r4ds.hadley.nz/datetimes) chapter in R for data science. 
-   [tidyverse](https://www.tidyverse.org/), a family of R packages for doing Data Science work based on tidy framework,
-   [tmap](https://r-tmap.github.io/tmap/index.html), an R package specially designed for plotting cartographical quality maps based on Layered Gremmar of Graphics.
-   [sf](https://r-spatial.github.io/sf/), an package that provides simple features access for R.

::: callout-note
### DIY

Write a code chunk to load the R packages into R environment.
:::

```{r}
pacman::p_load(arrow, lubridate, tidyverse, sf, tmap)
```

## Importing Grab-Posisi Dataset

::: callout-note
### DIY

-   Create a folder called *data* in *In-class_Ex02* folder.
-   Create a sub-folder called *GrabPosisi*.
-   Download, if you have yet to do so in previous lesson, Copy-and-Paste the downloaded data file into the newly created *GrabPosisi*.\
-   Write a code chunk to import *part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet* by using appropriate function of [**arrow**](https://arrow.apache.org/docs/r/index.html) package into R. Call the file *df*.
:::

```{r}
df <- read_parquet("data/GrabPosisi/part-00000.parquet")
```

::: callout-tip
### Thing to learn from the code chunk above

- [`read_parquet()`](https://arrow.apache.org/docs/r/reference/read_parquet.html) of **arrow** package in used to read parquet format into R. By default, the output file is in tibble data.frame.  
:::

## Data Preparation

### Converting data type

It is always a good practice to review the data type to ensure that they are in the correct data type format that meet you analysis need.

In the code chunk below, [`glimpse()`](https://dplyr.tidyverse.org/reference/glimpse.html) of **dplyr** package is used to display the structure of df tibble data.frame. 

```{r}
glimpse(df)
```

Notice that *pingtimestamp* is in wrong data type format.  It should be in date/time format and not integer.

::: callout-note
### DIY

Write a code chunk to convert the data type of *pingtimestamp* from character to date-time.

```{r}
#| eval: false
df$pingtimestamp <- as_datetime(df$pingtimestamp)
```
:::

::: callout-tip
### Thing to learn from the code chunk above

- [`as_datatime`](https://lubridate.tidyverse.org/reference/as_date.html) of lubridate package is used to convert *pingtimestamp* from integer to data-time data type.
:::

Before moving on to the next step, it is advisable to save the tidy data.frame into rds format for subsequent use.  RDS (R Data Serialization) files are a common format for saving R objects in RStudio, and they allow you to preserve the state of an object between R sessions. Saving your R object as an RDS file in R can be useful for sharing your work with others, replicating your analysis, or simply storing your work for later use.

::: callout-note
### DIY

Write a code chunk to save the reformatted df into a new rds file called *part0.rds*. Save the output into a sub-folder call *rds*.
:::

```{r}
#| eval: false
write_rds(df, "data/rds/part0.rds")
```

### Extracting trip starting locations

::: callout-note
### DIY

Using the step you learned in previous lesson,

-   extracting trips' origin locations.
-   derive three new columns (i.e. variables) for weekday, starting hour and day of the month.
-   name the output tibble data.frame *origin_df*.
:::

```{r}
#| eval: false
origin_df <- df %>% 
  group_by(trj_id) %>% 
  arrange(pingtimestamp) %>% 
  filter(row_number()==1) %>%
  mutate(weekday = wday(pingtimestamp,
                        label=TRUE,
                        abbr=TRUE),
         start_hr = factor(hour(pingtimestamp)),
         day = factor(mday(pingtimestamp)))
```

::: callout-tip
### Things to learn from the code chunk above

-   [`group_by()`](https://dplyr.tidyverse.org/reference/group_by.html) of **dplyr** is used to group the records according to the values of *trj_id*.
-   [`arrange()`](https://dplyr.tidyverse.org/reference/arrange.html) of **dplyr** package is used to sort the rows of a data frame by the values of selected column(s).  By default, the records will be sorted ascendingly.
-   [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) of dplyr is used to retaining all rows that meet the selection criteria (row_number()==1).
-   [`mutate()`](https://dplyr.tidyverse.org/reference/mutate.html) of dplyr is used to derive new fields by using functions.
-   [`wday()`](https://lubridate.tidyverse.org/reference/day.html) of lubridate package to return the day of the week.  By default, a full character of the day (i.e. Sunday) will be returned. The argument of *abbr=TRUE* will be used to return the abbreviation (i.e. Sun).     
-   [`hour()`](https://lubridate.tidyverse.org/reference/hour.html) returns hour of the day.
-   [`mday()`](https://lubridate.tidyverse.org/reference/day.html) returns the day of the month.
:::

### Extracting trip ending locations

::: callout-note
### DIY

Write a code chunk to extract trips' destination locations. Similarly, derive the weekday, ending hour and day of the month columns.
:::

```{r}
#| eval: false
destination_df <- df %>%
  group_by(trj_id) %>%
  arrange(desc(pingtimestamp)) %>%
  filter(row_number()==1) %>%
  mutate(weekday = wday(pingtimestamp,
                        label=TRUE,
                        abbr=TRUE),
         end_hr = factor(hour(pingtimestamp)),
         day = factor(mday(pingtimestamp)))
```

::: callout-tip
### Thing to learn from the code chunk above

-   arrange(desc(pingtimestamp)) is used to sort the values in *pingtimestamp* field descendingly.  This is necessary in order to retain the destination locations.
:::

::: callout-note
When you are happy with the quality of the tidied data, remember to save them for future used.
:::

```{r}
#| eval: false
write_rds(origin_df, "data/rds/origin_df.rds")
write_rds(destination_df, "data/rds/destination_df.rds")
```

If necessary, the code chunk below will be used to import the data.

```{r}
origin_df <- read_rds("data/rds/origin_df.rds")
destination_df <- read_rds("data/rds/destination_df.rds")
```

## Converting aspatial data into geospatial data

::: callout-note
### DIY

-   Convert *origin_df* into an sf tibble data.frame by using it's location information.
:::

```{r}
origin_sf <- st_as_sf(origin_df,
                      coords = c("rawlng", "rawlat"),
                      crs = 4326) %>%
  st_transform(crs = 3414)
```

::: callout-tip
Things to learn from the code chunk above

-   [`st_as_sf()`](https://r-spatial.github.io/sf/reference/st_as_sf.html) of sf package is used to convert the tibble data.frame into sf tibble data.frame. 
-   *coords* argument is used to specify the longitude and latitude fields.  It is important to note that it should start with longitude then follows by latitude.
-   *crs* argument must be used to specify the source coordinate system.
-   [`st_transform()`](https://r-spatial.github.io/sf/reference/st_transform.html) is used to transform from into a new coordinates system.
:::

## Visualising the data

After data preparation, it is always a good practice to visualise the data by using appropriate EDA or map visualisation methods.

### Visualising frequency distribution

In the code chunk below, ggplot functions are used to reveal the distribution of origin trips by day of the week.

```{r}
ggplot(data=origin_df, 
       aes(x=weekday)) + 
  geom_bar()
```

### Visualising as Point Symbol Map

In the code chunk below, tmap functions are used to plot a point symbol map by using the origin trips locations.

```{r}
tmap_mode("plot")
tm_shape(origin_sf) +
  tm_dots()
```

It is always useful for us to provide the map data a context.  

::: callout-info
### DIY

Using the step your learned from previous lesson, import Master Plan 2019 Subzone downloaded from data.Gov as sf tibble data.frame. Call the output *mpsz2019*.
:::

```{r}
mpsz2019 <- st_read("data/dataGov/MPSZ2019.kml") %>%
  st_transform(crs = 3414)
```

::: callout-info
### DIY

Using the step your learned, plot a point symbol map look similar to the figure below.
:::

```{r}
tm_shape(mpsz2019) +
  tm_polygons() +
tm_shape(origin_sf) +
  tm_dots()
```

::: callout-tip
Thing to learn from the code chunk above

-   For plotting multiple geospatial data layer.  Polygon layer will be plotted first, then followed by line or point layer or else the point or line features will be covered by the polygon features.

:::


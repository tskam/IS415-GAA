[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analyticvs and Applications.\nThis is the course website of IS415 I study this term. You will find my course work on this website."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "",
    "text": "maptools is retired and binary is removed from CRAN. However, we can download from Posit Public Package Manager snapshots by using the code chunk below.\n\n\ninstall.packages(\"maptools\", \n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#issue-1-installing-maptools",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#issue-1-installing-maptools",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Issue 1: Installing maptools",
    "text": "Issue 1: Installing maptools\nmaptools is retired and binary is removed from CRAN. However, we can download from Posit Public Package Manager snapshots by using the code chunk below.\n\n\ninstall.packages(\"maptools\", \n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#issue-1-installing-maptools-1",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#issue-1-installing-maptools-1",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Issue 1: Installing maptools",
    "text": "Issue 1: Installing maptools\n\n\nAfter the installation is completed, it is important to edit the code chunk as shown below in order to avoid maptools being download and install repetitively every time the Quarto document been rendered."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#issue-2-creating-coastal-outline",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#issue-2-creating-coastal-outline",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Issue 2: Creating coastal outline",
    "text": "Issue 2: Creating coastal outline\nIn sf package, there are two functions allow us to combine multiple simple features into one simple features. They are st_combine() and st_union().\nst_combine() returns a single, combined geometry, with no resolved boundaries; returned geometries may well be invalid.\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all unioned pairs of x[i] and y[j]."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#introducing-spatstat-package",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#introducing-spatstat-package",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Introducing spatstat package",
    "text": "Introducing spatstat package\nspatstat R package is a comprehensive open-source toolbox for analysing Spatial Point Patterns. Focused mainly on two-dimensional point patterns, including multitype or marked points, in any spatial region."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#spatstat",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#spatstat",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "spatstat",
    "text": "spatstat\nspatstat sub-packages\n\n\nThe spatstat package now contains only documentation and introductory material. It provides beginner’s introductions, vignettes, interactive demonstration scripts, and a few help files summarising the package.\nThe spatstat.data package now contains all the datasets for spatstat.\nThe spatstat.utils package contains basic utility functions for spatstat.\nThe spatstat.univar package contains functions for estimating and manipulating probability distributions of one-dimensional random variables.\nThe spatstat.sparse package contains functions for manipulating sparse arrays and performing linear algebra.\nThe spatstat.geom package contains definitions of spatial objects (such as point patterns, windows and pixel images) and code which performs geometrical operations.\nThe spatstat.random package contains functions for random generation of spatial patterns and random simulation of models.\nThe spatstat.explore package contains the code for exploratory data analysis and nonparametric analysis of spatial data.\nThe spatstat.model package contains the code for model-fitting, model diagnostics, and formal inference.\nThe spatstat.linnet package defines spatial data on a linear network, and performs geometrical operations and statistical analysis on such data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#creating-ppp-objects-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#creating-ppp-objects-from-sf-data.frame",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Creating ppp objects from sf data.frame",
    "text": "Creating ppp objects from sf data.frame\nInstead of using the two steps approaches discussed in Hands-on Exercise 3 to create the ppp objects, in this section you will learn how to work with sf data.frame.\n\n\nIn the code chunk below, as.ppp() of spatstat.geom package is used to derive an ppp object layer directly from a sf tibble data.frame.\n\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\n\nNext, summary() can be used to reveal the properties of the newly created ppp objects.\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#creating-owin-object-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#creating-owin-object-from-sf-data.frame",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Creating owin object from sf data.frame",
    "text": "Creating owin object from sf data.frame\n\n\nIn the code chunk as.owin() of spatstat.geom is used to create an owin object class from polygon sf tibble data.frame.\n\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\nNext, summary() function is used to display the summary information of the owin object class.\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#combining-point-events-object-and-owin-object",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#combining-point-events-object-and-owin-object",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Combining point events object and owin object",
    "text": "Combining point events object and owin object\n\nThe taskThe codeThe output\n\n\nUsing the step you learned from Hands-on Exercise 3, create an ppp object by combining childcare_ppp and sg_owin.\n\n\n\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\n\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#extracting-study-area-using-sf-objects",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#extracting-study-area-using-sf-objects",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Extracting study area using sf objects",
    "text": "Extracting study area using sf objects\n\nThe taskThe code\n\n\nExtract and create an ppp object showing child care services and within Punggol Planning Area\n\n\nOn the other hand, filter() of dplyr package should be used to extract the target planning areas as shown in the code chunk below.\n\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, I will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, I will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting the Geospatial Data",
    "text": "Plotting the Geospatial Data\n\nplot(mpsz)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "title": "In-class Exercise 2",
    "section": "Getting started",
    "text": "Getting started\n\nThe taskThe code\n\n\nFor the purpose of this in-class exercise, tidyverseand sf packages will be used. Write a code chunk to check if these two packages have been installed in R. If yes, load them in R environment.\n\n\n\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-planning-sub-zone-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-planning-sub-zone-data",
    "title": "In-class Exercise 2",
    "section": "Working with Master Plan Planning Sub-zone Data",
    "text": "Working with Master Plan Planning Sub-zone Data\n\nThe taskThe code\n\n\n\nCreate a sub-folder called data in In-class_Ex02 folder.\nIf necessary visit data.gov.sg and download Master Plan 2014 Subzone Boundary (Web) from the portal. You are required to download both the ESRI shapefile and kml file.\nWrite a code chunk to import Master Plan 2014 Subzone Boundary (Web) in shapefile and kml save them in sf simple features data frame.\n\n\n\n\nThis code chunk imports shapefile.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\tskam\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThis code chunk imports kml file.\n\nmpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-planning-sub-zone-data-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-planning-sub-zone-data-1",
    "title": "In-class Exercise 2",
    "section": "Working with Master Plan Planning Sub-zone Data",
    "text": "Working with Master Plan Planning Sub-zone Data\n\nThe taskThe code\n\n\n\nWrite a code chunk to export mpsz14_shp sf data.frame into kml file save the output in data sub-folder. Name the output file MP14_SUBZONE_WEB_PL.\n\n\n\n\n\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-pre-school-location-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-pre-school-location-data",
    "title": "In-class Exercise 2",
    "section": "Working with Pre-school Location Data",
    "text": "Working with Pre-school Location Data\n\nThe taskThe code\n\n\n\nIf necessary visit data.gov.sg and download Pre-Schools Location from the portal. You are required to download both the kml and geojson files.\nWrite a code chunk to import Pre-Schools Location in kml geojson save them in sf simple features data frame.\n\n\n\n\nThis code chunk imports kml file.\n\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\nThis code chunk imports geojson file.\n\npreschool_geojson &lt;- st_read(\"data/PreSchoolsLocation.geojson\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "title": "In-class Exercise 2",
    "section": "Working with Master Plan 2019 Subzone Boundary Data",
    "text": "Working with Master Plan 2019 Subzone Boundary Data\n\nThe taskTo import shapefileTo import kml\n\n\n\nVisit data.gov.sg and download Master Plan 2019 Subzone Boundary (No Sea) from the portal. You are required to download both the kml file.\nMove MPSZ-2019 shapefile provided for In-class Exercise 1 folder on elearn to data sub-folder of In-class_Ex02.\nWrite a code chunk to import Master Plan 2019 Subzone Boundary (No SEA) kml and MPSZ-2019 into sf simple feature data.frame.\n\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\tskam\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\tskam\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#handling-coordinate-systems",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#handling-coordinate-systems",
    "title": "In-class Exercise 2",
    "section": "Handling Coordinate Systems",
    "text": "Handling Coordinate Systems\nChecking coordinate system\n\nThe taskThe code\n\n\nWrite a code chunk to check the project of the imported sf objects.\n\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#handling-coordinate-systems-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#handling-coordinate-systems-1",
    "title": "In-class Exercise 2",
    "section": "Handling Coordinate Systems",
    "text": "Handling Coordinate Systems\nTransforming coordinate system\n\nThe taskTo import MPSZ-2019To import PreSchoolsLocation.kml\n\n\nRe-write the code chunk to import the Master Plan Sub-zone 2019 and Pre-schools Location with proper transformation\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\tskam\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\tskam\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-data-wrangling",
    "title": "In-class Exercise 2",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nPoint-in-Polygon count\n\nThe taskThe code\n\n\nWrite a code chunk to count the number of pre-schools in each planning sub-zone.\n\n\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-data-wrangling-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-data-wrangling-1",
    "title": "In-class Exercise 2",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nComputing density\n\nThe taskThe code\n\n\nWrite a single line code to perform the following tasks:\n\nDerive the area of each planning sub-zone.\nDrop the unit of measurement of the area (i.e. m^2)\nCalculate the density of pre-school at the planning sub-zone level.\n\n\n\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#statistical-analysis",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#statistical-analysis",
    "title": "In-class Exercise 2",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\n\nThe taskThe codeThe plot\n\n\nUsing appropriate Exploratory Data Analysis (EDA) and Confirmatory Data Analysis (CDA) methods to explore and confirm the statistical relationship between Pre-school Density and Pre-school count.\nTip: Refer to ggscatterstats() of ggstatsplot package.\n\n\n\n\nmpsz$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\nmpsz$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) \nmpsz19_shp &lt;- as.data.frame(mpsz19_shp)\n\nggscatterstats(data = mpsz19_shp,\n               x = `PreSch Density`,\n               y = `PreSch Count`,\n               type = \"parametric\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-population-data",
    "title": "In-class Exercise 2",
    "section": "Working with Population Data",
    "text": "Working with Population Data\n\nThe taskThe code\n\n\n\nVisit and extract the latest Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling from Singstat homepage.\n\n\n\n\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-wrangling",
    "title": "In-class Exercise 2",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nThe taskThe code\n\n\n\nWrite a code chunk to prepare a data.frame showing population by Planning Area and Planning subzone\n\n\n\n\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-processing",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-processing",
    "title": "In-class Exercise 2",
    "section": "Data Processing",
    "text": "Data Processing\n\nThe taskThe code\n\n\nWrite a code chunk to derive a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY where by:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#joining-popdata2023-and-mpsz19_shp",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#joining-popdata2023-and-mpsz19_shp",
    "title": "In-class Exercise 2",
    "section": "Joining popdata2023 and mpsz19_shp",
    "text": "Joining popdata2023 and mpsz19_shp\nThe code chunk below is used to change data in the PA and SZ fields into uppercase.\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \n\n\nThe code chunk below is used to perform left-join whereby the join fields are SUBZONE_N from the mpsz19_shp sf data.frame and SZ from the popdata2023 data.frame.\n\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "title": "In-class Exercise 2",
    "section": "Choropleth Map of Dependency Ratio by Planning Subzone",
    "text": "Choropleth Map of Dependency Ratio by Planning Subzone\n\nThe mapThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2023)+\n  \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  \n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            bg.color = \"#E4D5C9\",\n            frame = F) +\n  \n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics (DOS)\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#geospatial-analytics-for-social-good-myanmar-arm-conflict-case-study",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#geospatial-analytics-for-social-good-myanmar-arm-conflict-case-study",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Geospatial Analytics for Social Good: Myanmar Arm Conflict Case Study",
    "text": "Geospatial Analytics for Social Good: Myanmar Arm Conflict Case Study\n\nBackground\nMyanmar’s Troubled History: Coups, Military Rule, and Ethnic Conflict\nMyanmar conflict\nMyanmar civil war (2021–present)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#the-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#the-data",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "The Data",
    "text": "The Data\nArmed Conflict Location & Event Data (ACLED)\n\n\nAn independent, impartial, international non-profit organization collecting data on violent conflict and protest in all countries and territories in the world.\n\nGIS Data\n\nMyanmar Information Management Unit, MIMU"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation-of-spatial-point-event",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation-of-spatial-point-event",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation of Spatial Point Event",
    "text": "Kernel Density Estimation of Spatial Point Event\nThe code chunk below re-scale the unit of measurement from metre to kilometre before performing KDE.\n\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, \n                                  1000, \n                                  \"km\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(\n  childcareSG_ppp.km, \n  method=\"kernel\")\nplot(kde_childcareSG_adaptive)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\nCode chunk shown two different ways to convert KDE output into grid object\n\nmaptools methodspatstat.geom method\n\n\n\n\npar(bg = '#E4D5C9')\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation-1",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation-1",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\nVisualising KDE using tmap\nThe code chunk below is used to plot the output raster by using tmap functions.\n\n\ntm_shape(kde_childcareSG_ad_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE,\n            bg.color = \"#E4D5C9\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation-2",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#kernel-density-estimation-2",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\nVisualising KDE using tmap\n\ntm_shape(kde_childcareSG_ad_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE,\n            bg.color = \"#E4D5C9\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#importing-acled-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#importing-acled-data",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Importing ACLED Data",
    "text": "Importing ACLED Data\n\nThe taskThe code\n\n\nUsing the steps you learned in previous lessons, import the ACLED data into R environment as an sf tibble data.frame.\n\n\n\n\nacled_sf &lt;- read_csv(\"data/Myanmar/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#visualising-acled-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-SPAA.html#visualising-acled-data",
    "title": "In-class Exercise 3: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Visualising ACLED Data",
    "text": "Visualising ACLED Data\n\nThe taskThe code\n\n\nUsing the steps you learned in previous lessons, import the ACLED data into R environment as an sf tibble data.frame.\n\n\n\n\ntmap_mode(\"plot\")\nacled_sf %&gt;%\n  filter(year == 2023 | \n           event_type == \"Political violence\") %&gt;%\n  tm_shape()+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "",
    "text": "This in-class introduces an alternative R package to spdep package you used in Chapter 9: Global Measures of Spatial Autocorrelation and Chapter 10: Local Measures of Spatial Autocorrelation. The package is called sfdep. According to Josiah Parry, the developer of the package, “sfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#overview",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#overview",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "",
    "text": "This in-class introduces an alternative R package to spdep package you used in Chapter 9: Global Measures of Spatial Autocorrelation and Chapter 10: Local Measures of Spatial Autocorrelation. The package is called sfdep. According to Josiah Parry, the developer of the package, “sfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#getting-started",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#getting-started",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Getting started",
    "text": "Getting started\n\nInstalling and Loading the R Packages\nFour R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\n\n\n\n\n\nDo It Yourself!\n\n\n\nUsing the steps you learned in previous lesson, install and load sf, tmap, sfdep and tidyverse packages into R environment.\n\n\n\n\n\nShow the code\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#the-data",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\nImporting geospatial data\n\n\n\n\n\n\nDo It Yourself!\n\n\n\nUsing the steps you learned in previous lesson, import Hunan shapefile into R environment as an sf data frame.\n\n\n\n\n\nShow the code\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `D:\\tskam\\is415-gaa\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nImporting attribute table\n\n\n\n\n\n\nDo It Yourself!\n\n\n\nUsing the steps you learned in previous lesson, import Hunan_2012.csv into R environment as an tibble data frame.\n\n\n\n\n\nShow the code\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nCombining both data frame by using left join\n\n\n\n\n\n\nDo It Yourself!\n\n\n\nUsing the steps you learned in previous lesson, combine the Hunan sf data frame and Hunan_2012 data frame. Ensure that the output is an sf data frame.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)\n\n\n\n\n\nShow the code\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\nPlotting a choropleth map\n\n\n\n\n\n\nDo It Yourself!\n\n\n\nUsing the steps you learned in previous lesson, plot a choropleth map showing the distribution of GDPPC of Hunan Province.\n\n\nThe choropleth should look similar to the figure below.\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#global-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#global-measures-of-spatial-association",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Global Measures of Spatial Association",
    "text": "Global Measures of Spatial Association\n\nStep 1: Deriving contiguity weights: Queen’s method\n\n\n\n\n\n\nDo it Yourself!\n\n\n\nUsing the steps you learned in previous lesson, derive a Queen’s contiguity weights by using appropriate spdep and tidyverse functions.\n\n\n\n\nDeriving contiguity weights: Queen’s method\nIn the code chunk below, queen method is used to derive the contiguity weights.\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n\n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbor list object as created by st_neighbors().\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nComputing Global Moran’ I\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nPerforming Global Moran’sI test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\nBy default the randomization argument is TRUE. If FALSE, under the assumption of normality.\n\n\n\n\n\nPerforming Global Moran’I permutation test\nIn practice, monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm()\nIt is alway a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\nset.seed(1234)\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n\n\n\n\n\nReminder\n\n\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#computing-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Computing local Moran’s I",
    "text": "Computing local Moran’s I\nIn this section, you will learn how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\n\nVisualising local Moran’s I\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\n\n\n\n\n\n\n\n\n\n\nVisualising p-value of local Moran’s I\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme.\n\n\n\n\nVisuaising local Moran’s I and p-value\nFor effective comparison, it will be better for us to plot both maps next to each other as shown below.\n\n\n\nShow the code\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising LISA map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Hot Spot and Cold Spot Area Analysis (HCSA)",
    "text": "Hot Spot and Cold Spot Area Analysis (HCSA)\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#computing-local-gi-statistics",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#computing-local-gi-statistics",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Computing local Gi* statistics",
    "text": "Computing local Gi* statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\n\n\nNow, we will compute the local Gi* by using the code chunk below.\n\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\nVisualising Gi*\n\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\n\n\n\n\n\n\nVisualising p-value of HCSA\n\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nVisuaising local HCSA\nFor effective comparison, you can plot both maps next to each other as shown below.\n\n\n\nShow the code\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#visualising-hot-spot-and-cold-spot-areas",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-GLSA.html#visualising-hot-spot-and-cold-spot-areas",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Visualising hot spot and cold spot areas",
    "text": "Visualising hot spot and cold spot areas\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex04.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\tskam\\is415-gaa\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords,\n                          longlat = TRUE))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex04.html#working-with-geographically-weighted-summary-statistics-gwss",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex04.html#working-with-geographically-weighted-summary-statistics-gwss",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep methods",
    "section": "Working with Geographically Weighted Summary Statistics (GWSS)",
    "text": "Working with Geographically Weighted Summary Statistics (GWSS)\n\nhunan_sp &lt;- hunan %&gt;%\n  as_Spatial()\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = 6,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "",
    "text": "pacman::p_load(sf, tmap, sfdep, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#importing-province-boundary-data-without-islands",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#importing-province-boundary-data-without-islands",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Importing Province Boundary Data (without islands)",
    "text": "Importing Province Boundary Data (without islands)\n\nImporting the province boundary data\n\nprov_sf &lt;- st_read(dsn = \"data/rawdata\",\n                   layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `D:\\tskam\\is415-gaa\\Take-home_Ex\\Take-home_Ex2\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(prov_sf) +\n  tm_polygons()\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\nConvert multipolygon to individual polygons\nCalculate the area of each polygon\n\nsf_polygon &lt;- prov_sf %&gt;%\n  st_cast(\"POLYGON\") %&gt;%\n  mutate(area = st_area(.))  \n\n\n\nGroup by the unique name and select the largest polygon by area\n\nprov_cleaned &lt;- sf_polygon %&gt;%\n  group_by(ADM1_EN) %&gt;%  \n  filter(area == max(area)) %&gt;%\n  ungroup() %&gt;%\n  select(-area) %&gt;%\n  select(ADM1_EN)\n\nReplace ‘prov_name’ with your actual name column Optionally remove the area column if not needed\n\n\nView the resulting data frame\n\nprov_cleaned\n\n\n\nWriting output\n\nwrite_rds(prov_cleaned,\n          \"data/sandbox/prov_cleaned.rds\")\n\n\nprov_cleaned &lt;- read_rds(\n  \"data/sandbox/prov_cleaned.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#preparing-the-attribute-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#preparing-the-attribute-data",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Preparing the Attribute Data",
    "text": "Preparing the Attribute Data\n\ndrug &lt;- read.csv(\"data/rawdata/thai_drug_offenses_2017_2022.csv\")\n\nSeveral data issues have been identified, they are:\n\ndrug &lt;- read.csv(\"data/rawdata/thai_drug_offenses_2017_2022.csv\") %&gt;%\n  mutate(province_en = str_trim(province_en)) %&gt;%\n  rename(ADM1_EN = province_en) %&gt;%\n  select(c(fiscal_year, types_of_drug_offenses, \n           no_cases, ADM1_EN)) %&gt;%\n  pivot_wider(names_from = types_of_drug_offenses,\n              values_from = no_cases)\n\n\ndrug_cleaned &lt;- drug %&gt;%\n  mutate(ADM1_EN = case_when(\n    ADM1_EN == \"buogkan\" ~ \"Bueng Kan\",\n    ADM1_EN == \"Loburi\" ~ \"Lop Buri\",\n    TRUE ~ ADM1_EN  # Keep the correct names as is\n  ))\n\n\nwrite_rds(drug_cleaned,\n          \"data/sandbox/drug_cleaned.rds\")\n\n\ndrug_cleaned &lt;- read_rds(\"data/sandbox/drug_cleaned.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#exploring-and-analysing-time-series-patterns-of-the-event",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#exploring-and-analysing-time-series-patterns-of-the-event",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Exploring and Analysing Time-series patterns of the event",
    "text": "Exploring and Analysing Time-series patterns of the event\n\nStep 1: Create the bar plot\n\nggplot(drug_cleaned, \n       aes(x = fiscal_year, \n           y = drug_use_cases)) +\n  geom_bar(stat = \"identity\", \n           fill = \"steelblue\") + \n  labs(title = \"Total drug use cases\",\n       x = \"Year\",\n       y = \"Total cases\") +\n  theme(axis.text.x = element_text(\n    angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat can your learn from the code chunk above?\n\n\n\n\nmutate(Month_Year = floor_date(Date, “month”)): This creates a new column Month_Year by flooring the Date to the first day of the month, effectively grouping by month-year.\ngroup_by(Month_Year): Groups the data by the new Month_Year column.\nsummarise(Total_Revenue = sum(Revenue, na.rm = TRUE)): Aggregates the total revenue for each month-year.\nggplot(df_monthly, aes(x = Month_Year, y = Total_Revenue)): Sets up the plot with Month_Year on the x-axis and Total_Revenue on the y-axis.\ngeom_bar(stat = “identity”, fill = “steelblue”): Creates a bar plot with bars filled in steel blue.\nscale_x_date(date_labels = “%b-%Y”, date_breaks = “1 month”): Formats the x-axis to display the month-year labels.\ntheme(axis.text.x = element_text(angle = 45, hjust = 1)): Rotates the x-axis labels for better readability."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#exploring-and-visualising-spatial-distribution-over-time",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#exploring-and-visualising-spatial-distribution-over-time",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Exploring and Visualising Spatial Distribution Over Time",
    "text": "Exploring and Visualising Spatial Distribution Over Time\n\nprov_drug &lt;- prov_cleaned %&gt;%\n  left_join(drug_cleaned)\n\nJoining with `by = join_by(ADM1_EN)`"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#creating-a-time-series-cube",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#creating-a-time-series-cube",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Creating a Time Series Cube",
    "text": "Creating a Time Series Cube\n\ndrug_cube &lt;- spacetime(drug_cleaned, \n                       prov_cleaned, \n                       \"ADM1_EN\", \n                       \"fiscal_year\")\n\n\nChecking the time series cube\n\nclass(drug_cube)\n\n[1] \"spacetime\"  \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nis_spacetime_cube(drug_cube)\n\n[1] TRUE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#deriving-the-spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#deriving-the-spatial-weights",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Deriving the Spatial Weights",
    "text": "Deriving the Spatial Weights\n\ndrug_nb &lt;- drug_cube %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(\n    nb = include_self(st_knn(geometry, k = 8)),\n    wt = st_inverse_distance(nb, geometry,\n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n! Polygon provided. Using point on surface."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#computing-local-morons-i",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#computing-local-morons-i",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Computing local Moron’s I",
    "text": "Computing local Moron’s I\n\nlm_i &lt;- drug_nb %&gt;%\n  group_by(fiscal_year) %&gt;%\n  mutate(local_moran = local_moran(\n    drug_use_cases,\n    nb, wt,\n    nsim = 199),\n    .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nLISAMap &lt;- prov_cleaned %&gt;%\n  left_join(lm_i,\n            by = join_by(\n              ADM1_EN == ADM1_EN))\n\n\ntm_shape(LISAMap) +\n  tm_fill(\"ii\",\n          style = \"quantile\",\n          title = \"Drug use cases\",\n          palette = \"Blues\") +  \n  tm_borders() +  \n  tm_facets(by = \"fiscal_year\", \n            free.coords = FALSE) +  \n  tm_layout(title = \"Drug use cases by year\",\n            legend.outside = TRUE,  \n            panel.label.size = 1)\n\n\n\n\n\n\n\n\n\ntm_shape(LISAMap) +\n  tm_fill(\"mean\") +  \n  tm_borders() +  \n  tm_facets(by = \"fiscal_year\", \n            free.coords = FALSE) +  \n  tm_layout(title = \"Drug use cases by year\",\n            legend.outside = TRUE,  \n            panel.label.size = 1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#computing-gi",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#computing-gi",
    "title": "Take-home Exercise 2: Drug Offenses",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\nehsa_drug &lt;- emerging_hotspot_analysis(\n  x = drug_cube,\n  .var = \"drug_use_cases\",\n  k = 1,\n  nsim = 99\n)\n\n\nVisualising the distribution of EHSA class\n\nggplot(data = ehsa_drug,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nMapping the classes\n\nprov_ehsa &lt;- prov_cleaned %&gt;%\n  left_join(ehsa_drug,\n            by = join_by(ADM1_EN == location))\n\n\nehsa_sig &lt;- prov_ehsa %&gt;%\n  filter(p_value &lt; 0.1)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(prov_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nLegend labels were too wide. The labels have been resized to 0.50, 0.52, 0.60. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Geographically Weighted Statistics - gwModel methods",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\tskam\\is415-gaa\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords,\n                          longlat = TRUE))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#working-with-geographically-weighted-summary-statistics-gwss",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#working-with-geographically-weighted-summary-statistics-gwss",
    "title": "In-class Exercise 5: Geographically Weighted Statistics - gwModel methods",
    "section": "Working with Geographically Weighted Summary Statistics (GWSS)",
    "text": "Working with Geographically Weighted Summary Statistics (GWSS)\n\nhunan_sp &lt;- hunan %&gt;%\n  as_Spatial()\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = 6,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#overview",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#overview",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#learning-outcome",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Learning Outcome",
    "text": "Learning Outcome\n\nThe research questions\nThe specific questions we would like to answer are:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#the-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#the-data",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "The data",
    "text": "The data\nFor the purpose of this exercise, two data sets will be used, they are:\n\nforestfires, a csv file provides locations of forest fire detected from the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor data. The data are downloaded from Fire Information for Resource Management System. For the purpose of this exercise, only forest fires within Kepulauan Bangka Belitung will be used.\n\nKepulauan_Bangka_Belitung, an ESRI shapefile showing the sub-district (i.e. kelurahan) boundary of Kepulauan Bangka Belitung. The data set was downloaded from Indonesia Geospatial portal. The original data covers the whole Indonesia. For the purpose of this exercise, only sub-districts within Kepulauan Bangka Belitung are extracted."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#installing-and-loading-the-r-packages",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Installing and Loading the R packages",
    "text": "Installing and Loading the R packages\nFor the purpose of this study, seven R packages will be used. They are:\n\nsf provides functions for importing processing and wrangling geospatial data,,\nraster for handling raster data in R,\nspatstat for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc.,\nsparr provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported\nstopp provides functions to perform 1st and 2nd-order spatio-temporal point patterns analysis, and\ntmap provides functions to produce cartographic quality thematic maps, and\ntidyverse, a family of R packages that provide functions to perform common data science tasks including and not limited to data import, data transformation, data wrangling and data visualisation.\n\n\nDIYThe solution\n\n\nUsing the steps you learned from previous chapter, write a code chunk to load the packages above onto R environment.\n\n\n\npacman::p_load(sf, raster, spatstat, sparr, stopp, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#importing-and-preparing-study-area",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#importing-and-preparing-study-area",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Importing and Preparing Study Area",
    "text": "Importing and Preparing Study Area\n\nImporting study area\nCode chunk below is used import study area (i.e. Kepulauan Bangka Belitung) into R environment.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_transform(crs = 32748)\n\nThe revised code chunk.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `D:\\tskam\\is415-gaa\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nConverting OWIN\nNext, as.owin() is used to convert kbb into an owin object.\n\nkbb_owin &lt;- as.owin(kbb)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nNext, class() is used to confirm if the output is indeed an owin object.\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#importing-and-preparing-forest-fire-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#importing-and-preparing-forest-fire-data",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Importing and Preparing Forest Fire data",
    "text": "Importing and Preparing Forest Fire data\nNext, we will import the forest fire data set (i.e. forestfires.csv) into R environment.\n\nff &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n                       crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nBecause ppp object only accept numerical or character as mark. The code chunk below is used to convert data type of acq_date to numeric.\n\nff &lt;- ff %&gt;% \n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date, \n                           label = TRUE, \n                           abbr = FALSE))\n\n\ntm_shape(kbb)+\n  tm_polygons() +\ntm_shape(ff) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\ntm_shape(kbb)+\n  tm_polygons() +\ntm_shape(ff) +\n  tm_dots(size = 0.1) +\ntm_facets(by=\"Month_fac\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\nff_month &lt;- ff %&gt;% \n  select(Month_num)\n\nThe code chunk below is used to remove the unwanted fields from origin_am sf data.frame. This is because as.ppp() only need the mark field and geometry field from the input sf data.frame.\n\nCreating ppp\nThe code chunk below is used to derive a ppp object called origin_am_ppp from origin_am sf data.frame.\n\nff_month_ppp &lt;- as.ppp(ff_month)\nff_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nThe code chunk below is used to check the output is in the correct object class.\n\nsummary(ff_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\nNext, we will check if there are duplicated point events by using the code chunk below.\n\nany(duplicated(ff_month_ppp))\n\n[1] FALSE\n\n\n\n\nIncluding Owin object\nThe code chunk below is used to combine origin_am_ppp and am_owin objects into one.\n\nff_month_owin &lt;- ff_month_ppp[kbb_owin]\nsummary(ff_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\nAs a good practice, plot() is used to plot ff_owin so that we can examine the correctness of the output object.\n\nplot(ff_month_owin)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#computing-spatio-temporal-kde",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#computing-spatio-temporal-kde",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing Spatio-temporal KDE",
    "text": "Computing Spatio-temporal KDE\nIn the code chunk below, spattemp.density() of sparr package is used to compute the spatial-temporal KDE by using origin_am_ppp as the input.\n\nst_kde &lt;- spattemp.density(ff_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\nPlotting the spatio-temporal KDE object\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#section",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04_stpp.html#section",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "ff_yday_ppp &lt;- ff %&gt;% \n  select(DayofYear) %&gt;%\n  as.ppp()\n\n\nff_yday_owin &lt;- ff_yday_ppp[kbb_owin]\nsummary(ff_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\nbw &lt;- BOOT.spattemp(ff_yday_owin) \n\nInitialising...Done.\nOptimising...\nh = 15102.47 \b; lambda = 16.84806 \nh = 16612.72 \b; lambda = 16.84806 \nh = 15102.47 \b; lambda = 1527.095 \nh = 15480.03 \b; lambda = 771.9715 \nh = 15668.81 \b; lambda = 394.4098 \nh = 15763.2 \b; lambda = 205.6289 \nh = 15810.4 \b; lambda = 111.2385 \nh = 15833.99 \b; lambda = 64.04328 \nh = 15845.79 \b; lambda = 40.44567 \nh = 15851.69 \b; lambda = 28.64687 \nh = 15863.49 \b; lambda = 5.049258 \nh = 15854.64 \b; lambda = 22.74746 \nh = 15860.54 \b; lambda = 10.94866 \nh = 15859.07 \b; lambda = 13.89836 \nh = 14348.82 \b; lambda = 13.89836 \nh = 13216.87 \b; lambda = 12.42351 \nh = 12460.27 \b; lambda = 15.37321 \nh = 10760.88 \b; lambda = 16.11064 \nh = 8875.282 \b; lambda = 11.68608 \nh = 10432.08 \b; lambda = 12.97658 \nh = 7976.084 \b; lambda = 16.66371 \nh = 9286.281 \b; lambda = 15.60366 \nh = 9615.08 \b; lambda = 18.73771 \nh = 9206.581 \b; lambda = 21.61828 \nh = 8140.483 \b; lambda = 18.23073 \nh = 8795.582 \b; lambda = 17.70071 \nh = 9124.381 \b; lambda = 20.83477 \nh = 9164.856 \b; lambda = 19.52699 \nh = 8345.358 \b; lambda = 18.48998 \nh = 9297.65 \b; lambda = 18.67578 \nh = 8928.375 \b; lambda = 16.8495 \nh = 9105.736 \b; lambda = 18.85762 \nDone.\n\n\n\n\n\nkde_yday &lt;- spattemp.density(\n  ff_yday_owin,\n  h = 9105.7,\n  lambda = 18.9)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9105.7 (spatial)\n  lambda = 18.9 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [1.87138e-19, 2.427975e-12]\n\n\n\nplot(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#overview",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#overview",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#learning-outcome",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Learning Outcome",
    "text": "Learning Outcome\n\nThe research questions\nThe specific questions we would like to answer are:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#the-data",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#the-data",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "The data",
    "text": "The data\nFor the purpose of this exercise, two data sets will be used, they are:\n\nforestfires, a csv file provides locations of forest fire detected from the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor data. The data are downloaded from Fire Information for Resource Management System. For the purpose of this exercise, only forest fires within Kepulauan Bangka Belitung will be used.\n\nKepulauan_Bangka_Belitung, an ESRI shapefile showing the sub-district (i.e. kelurahan) boundary of Kepulauan Bangka Belitung. The data set was downloaded from Indonesia Geospatial portal. The original data covers the whole Indonesia. For the purpose of this exercise, only sub-districts within Kepulauan Bangka Belitung are extracted."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#installing-and-loading-the-r-packages",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Installing and Loading the R packages",
    "text": "Installing and Loading the R packages\nFor the purpose of this study, six R packages will be used. They are:\n\nsf provides functions for importing processing and wrangling geospatial data,,\nraster for handling raster data in R,\nspatstat for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc.,\nsparr provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported\ntmap provides functions to produce cartographic quality thematic maps, and\ntidyverse, a family of R packages that provide functions to perform common data science tasks including and not limited to data import, data transformation, data wrangling and data visualisation.\n\n\nDIYThe solution\n\n\nUsing the steps you learned from previous chapter, write a code chunk to load the packages above onto R environment.\n\n\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#importing-and-preparing-study-area",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#importing-and-preparing-study-area",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Importing and Preparing Study Area",
    "text": "Importing and Preparing Study Area\n\nImporting study area\nCode chunk below is used import study area (i.e. Kepulauan Bangka Belitung) into R environment.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_transform(crs = 32748)\n\nThe revised code chunk.\n\nkbb_sf &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `D:\\tskam\\is415-gaa\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nConverting OWIN\nNext, as.owin() is used to convert kbb into an owin object.\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nNext, class() is used to confirm if the output is indeed an owin object.\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#importing-and-preparing-forest-fire-data",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#importing-and-preparing-forest-fire-data",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Importing and Preparing Forest Fire data",
    "text": "Importing and Preparing Forest Fire data\nNext, we will import the forest fire data set (i.e. forestfires.csv) into R environment.\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n                       crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nBecause ppp object only accept numerical or character as mark. The code chunk below is used to convert data type of acq_date to numeric.\n\nfire_sf &lt;- fire_sf %&gt;% \n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date, \n                           label = TRUE, \n                           abbr = FALSE))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#visualising-the-fire-points",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#visualising-the-fire-points",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Visualising the Fire Points",
    "text": "Visualising the Fire Points\n\nOverall plot\n\nDIYThe code\n\n\nUsing the steps you learned in Hands-on Exercise 2, prepare a point symbol map showing the distribution of fire points. The map should look similar to the figure below.\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisuaising geographic distribution of forest fires by month\n\nDIYThe code\n\n\nUsing the steps you learned in Hands-on Exercise 2, prepare a point symbol map showing the monthly geographic distribution of forest fires in 2023. The map should look similar to the figure below.\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\ntm_facets(by=\"Month_fac\", \n            free.coords=FALSE, \n            drop.units = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#computing-stkde-by-month",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#computing-stkde-by-month",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing STKDE by Month",
    "text": "Computing STKDE by Month\nIn this section, you will learn how to compute STKDE by using spattemp.density() of sparr package. Before using the function, it is highly recommended you read the function’s reference guide in detail in order to understand the input data requirements and the output object generated.\n\nExtracting forest fires by month\nThe code chunk below is used to remove the unwanted fields from fire_sf sf data.frame. This is because as.ppp() only need the mark field and geometry field from the input sf data.frame.\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)\n\n\n\nCreating ppp\nThe code chunk below is used to derive a ppp object called fire_month from fire_month sf data.frame.\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nThe code chunk below is used to check the output is in the correct object class.\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\nNext, we will check if there are duplicated point events by using the code chunk below.\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\n\nIncluding Owin object\nThe code chunk below is used to combine origin_am_ppp and am_owin objects into one.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\nAs a good practice, plot() is used to plot ff_owin so that we can examine the correctness of the output object.\n\nplot(fire_month_owin)\n\n\n\n\n\n\n\n\n\n\nComputing Spatio-temporal KDE\nNext, spattemp.density() of sparr package is used to compute the STKDE.\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\n\nPlotting the spatio-temporal KDE object\nIn the code chunk below, plot() of R base is used to the KDE for between July 2023 - December 2023.\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#computing-stkde-by-day-of-year",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#computing-stkde-by-day-of-year",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing STKDE by Day of Year",
    "text": "Computing STKDE by Day of Year\nIn this section, you will learn how to computer the STKDE of forest fires by day of year.\n\nCreating ppp object\nIn the code chunk below, DayofYear field is included in the output ppp object.\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayofYear) %&gt;%\n  as.ppp()\n\n\n\nIncluding Owin object\nNext, code chunk below is used to combine the ppp object and the owin object.\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\n\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]\n\n\n\nplot(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#computing-stkde-by-day-of-year-improved-method",
    "href": "In-class_Ex/In-class_Ex04/In-class Ex04-stpp.html#computing-stkde-by-day-of-year-improved-method",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing STKDE by Day of Year: Improved method",
    "text": "Computing STKDE by Day of Year: Improved method\nOne of the nice function provides in sparr package is BOOT.spattemp(). It support bandwidth selection for standalone spatiotemporal density/intensity based on bootstrap estimation of the MISE, providing an isotropic scalar spatial bandwidth and a scalar temporal bandwidth.\nCode chunk below uses BOOT.spattemp() to determine both the spatial bandwidth and the scalar temporal bandwidth.\n\nset.seed(1234)\nBOOT.spattemp(fire_yday_owin) \n\nInitialising...Done.\nOptimising...\nh = 15102.47 \b; lambda = 16.84806 \nh = 16612.72 \b; lambda = 16.84806 \nh = 15102.47 \b; lambda = 1527.095 \nh = 15480.03 \b; lambda = 771.9715 \nh = 15668.81 \b; lambda = 394.4098 \nh = 15763.2 \b; lambda = 205.6289 \nh = 15810.4 \b; lambda = 111.2385 \nh = 15833.99 \b; lambda = 64.04328 \nh = 15845.79 \b; lambda = 40.44567 \nh = 15851.69 \b; lambda = 28.64687 \nh = 15863.49 \b; lambda = 5.049258 \nh = 15854.64 \b; lambda = 22.74746 \nh = 15860.54 \b; lambda = 10.94866 \nh = 15859.07 \b; lambda = 13.89836 \nh = 14348.82 \b; lambda = 13.89836 \nh = 13216.87 \b; lambda = 12.42351 \nh = 12460.27 \b; lambda = 15.37321 \nh = 10760.88 \b; lambda = 16.11064 \nh = 8875.282 \b; lambda = 11.68608 \nh = 10432.08 \b; lambda = 12.97658 \nh = 7976.084 \b; lambda = 16.66371 \nh = 9286.281 \b; lambda = 15.60366 \nh = 9615.08 \b; lambda = 18.73771 \nh = 9206.581 \b; lambda = 21.61828 \nh = 8140.483 \b; lambda = 18.23073 \nh = 8795.582 \b; lambda = 17.70071 \nh = 9124.381 \b; lambda = 20.83477 \nh = 9164.856 \b; lambda = 19.52699 \nh = 8345.358 \b; lambda = 18.48998 \nh = 9297.65 \b; lambda = 18.67578 \nh = 8928.375 \b; lambda = 16.8495 \nh = 9105.736 \b; lambda = 18.85762 \nDone.\n\n\n         h     lambda \n9105.73611   18.85762 \n\n\nNow, the STKDE will be derived by using\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,\n  h = 9000,\n  lambda = 19)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]\n\n\n\nplot(kde_yday)"
  }
]